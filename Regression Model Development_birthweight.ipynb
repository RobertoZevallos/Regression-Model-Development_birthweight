{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24862126",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1>Regression Model Development</h1>\n",
    "\n",
    "<em><strong>Roberto Zevallos</strong></em>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "To start, I imported the birth weight Excel file and I checked the size of my dataset, where I identified that it doesn't have many observations (196) and 18 features.\n",
    "<br>\n",
    "Then the .info() function helped me check the information of my data, like validation of data types. By using the .isnull() function I identified missing values in three features (father's education, number of prenatal visits and mother's education).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34006883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import numpy as np # mathematical essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns # enhanced graphical output\n",
    "import statsmodels.formula.api as smf # predictive modeling with nice outputs\n",
    "\n",
    "# setting file name\n",
    "file = './birthweight_low.xlsx'\n",
    "\n",
    "birthweight = pd.read_excel(io         = file,\n",
    "                            header     = 0,\n",
    "                            sheet_name = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bba536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Size of Original Dataset\n",
    "------------------------\n",
    "Observations: {birthweight.shape[0]}\n",
    "Features:     {birthweight.shape[1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35988337",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthweight.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14000285",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthweight.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577037d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Flagging missing values</strong>\n",
    "<br>\n",
    "To point out the missing values I used a loop to flag them and added new columns at the end of the dataset with \"1\" were the missing values were found. These new columns are codified by adding a letter \"m\" from missing the beginning of their name.\n",
    "Then a sum of missing values was done to validate that all the missing values were identified.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag the missing values\n",
    "for column in birthweight:\n",
    "\n",
    "    if birthweight[column].isnull().astype(int).sum() > 0:\n",
    "        birthweight['m_' + column] = birthweight[column].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f82286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of missing values\n",
    "print(f\"\"\"\n",
    "Sums of Missing Value Flags\n",
    "--------------------------\n",
    "{birthweight.iloc[ : , -3: ].sum(axis = 0)}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6c37e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Treatment of missing values</strong>\n",
    "<br>\n",
    "To treat the missing values I created a new DataFrame were I dropped the previously identified missing values. This was done to identify the mode and median of this dataset and to be able to compare the new data once I had imputed the missing values.\n",
    "<br><br>\n",
    "By looking at the histograms for each variable that had missing values, I decided that the best imputation method was to use the median for the missing values. I did not use the mean because it includes decimals and to make more sense with the data the median seems more appropriate. Also, there wasn't a big difference in the impact in the distribution between imputing with the mean or median. \n",
    "<br><br>\n",
    "Further, by using the .fillna() function, the missing values were imputed with the median.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing values and creating a new DataFrame\n",
    "birthweight_dropped = pd.DataFrame.copy(birthweight)\n",
    "\n",
    "birthweight_dropped = birthweight_dropped.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthweight_dropped.describe(include = 'number').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram for feduc\n",
    "sns.histplot(data  = birthweight_dropped,\n",
    "             x     ='feduc',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # kernel decimal estimate, draw the distribution\n",
    "             color = 'gray')\n",
    "\n",
    "\n",
    "# adding a title\n",
    "plt.title(label = \"Distribution of father education\")\n",
    "\n",
    "\n",
    "# adding an x-label\n",
    "plt.xlabel(xlabel = 'Father education')\n",
    "\n",
    "\n",
    "# adding a y-label\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "\n",
    "# adding a mean and median line\n",
    "plt.axvline(x = birthweight_dropped['feduc'].mean(),\n",
    "            color = 'red')\n",
    "\n",
    "plt.axvline(x = birthweight_dropped['feduc'].median(),\n",
    "            color = 'blue')\n",
    "\n",
    "# adding legend\n",
    "plt.legend(labels =  ['bins','mean', 'median'])\n",
    "\n",
    "# displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "########\n",
    "# histogram for meduc\n",
    "sns.histplot(data  = birthweight_dropped,\n",
    "             x     ='meduc',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # kernel decimal estimate, draw the distribution\n",
    "             color = 'gray')\n",
    "\n",
    "\n",
    "# adding a title\n",
    "plt.title(label = \"Distribution of mother education\")\n",
    "\n",
    "\n",
    "# adding an x-label\n",
    "plt.xlabel(xlabel = 'Mother education')\n",
    "\n",
    "\n",
    "# adding a y-label\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "\n",
    "# adding a mean and median line\n",
    "plt.axvline(x = birthweight_dropped['meduc'].mean(),\n",
    "            color = 'red')\n",
    "\n",
    "plt.axvline(x = birthweight_dropped['meduc'].median(),\n",
    "            color = 'blue')\n",
    "\n",
    "# adding legend\n",
    "plt.legend(labels =  ['bins','mean', 'median'])\n",
    "\n",
    "# displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#######\n",
    "# histogram for npvis\n",
    "sns.histplot(data  = birthweight_dropped,\n",
    "             x     ='npvis',\n",
    "             bins  = 'fd',\n",
    "             kde   = True, # kernel decimal estimate, draw the distribution\n",
    "             color = 'gray')\n",
    "\n",
    "\n",
    "# adding a title\n",
    "plt.title(label = \"Distribution of number of prenatal visits\")\n",
    "\n",
    "\n",
    "# adding an x-label\n",
    "plt.xlabel(xlabel = 'Prenatal visits')\n",
    "\n",
    "\n",
    "# adding a y-label\n",
    "plt.ylabel(ylabel = 'Frequency')\n",
    "\n",
    "# adding a mean and median line\n",
    "plt.axvline(x = birthweight_dropped['npvis'].mean(),\n",
    "            color = 'red')\n",
    "\n",
    "plt.axvline(x = birthweight_dropped['npvis'].median(),\n",
    "            color = 'blue')\n",
    "\n",
    "# adding legend\n",
    "plt.legend(labels =  ['bins','mean', 'npvis'])\n",
    "\n",
    "# displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meduc_median = birthweight['meduc'].median()\n",
    "\n",
    "\n",
    "# filling meduc NAs with MEDIAN\n",
    "birthweight['meduc'].fillna(value = meduc_median,\n",
    "                         inplace = True)\n",
    "\n",
    "\n",
    "# checking to make sure NAs are filled in\n",
    "print(birthweight['meduc'].isnull().any())\n",
    "\n",
    "\n",
    "npvis_median = birthweight['npvis'].median()\n",
    "\n",
    "\n",
    "# filling npvis NAs with MEDIAN\n",
    "birthweight['npvis'].fillna(value = npvis_median,\n",
    "                         inplace = True)\n",
    "\n",
    "\n",
    "# checking to make sure NAs are filled in\n",
    "print(birthweight['npvis'].isnull().any())\n",
    "\n",
    "\n",
    "\n",
    "feduc_median = birthweight['feduc'].median()\n",
    "\n",
    "\n",
    "# filling feduc NAs with MEDIAN\n",
    "birthweight['feduc'].fillna(value = feduc_median,\n",
    "                         inplace = True)\n",
    "\n",
    "\n",
    "# checking to make sure NAs are filled in\n",
    "print(birthweight['feduc'].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1960a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation of imputed values for feduc and comparing with the education and age from the mother\n",
    "birthweight.loc[:,[\"meduc\", \"feduc\", \"mage\"]][birthweight.loc[:,\"m_feduc\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure little change on values with the imputaion \n",
    "birthweight.describe(include = 'number').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1fedf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Validating features and target variable distributions</strong>\n",
    "<br>\n",
    "This section was used to create histograms to identify the distribution of each feature and the response variable to determine if using a log could be useful during the engineering process.\n",
    "<br><br>\n",
    "Only four histograms were left in the final code to keep it simple, but the arguments of the histograms were modified in this section to look at the different variables before and after the engineering process. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14dd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# birthweight\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'bwght',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Birthweight\")\n",
    "plt.xlabel(xlabel = \"Birthweight\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "# cigs\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'cigs',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Avg Cigarettes per week\")\n",
    "plt.xlabel(xlabel = \"Avg Cigarettes per week\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "# drinks\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'drink',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Avg Drinks per week\")\n",
    "plt.xlabel(xlabel = \"Avg Drinks per week\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# mage\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'mage',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Mother's age\")\n",
    "plt.xlabel(xlabel = \"Mother's age\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fage\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'fage',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Fathers's age\")\n",
    "plt.xlabel(xlabel = \"Father's age\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1cba1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Correlations</strong>\n",
    "<br>\n",
    "Different correlation matrix were developed in this section by setting one single variable to easily compare its correlation to the other variables.\n",
    "<br>\n",
    "In the example that is kept in the code, I can see that the variables drink, cigs, mage and fage could probably lead to a better model. However, it was also important to obtain the correlation of these variables among them to identify possible multi-collinearity.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing a correlation matrix\n",
    "birthweight_corr = birthweight.corr(method = 'pearson')\n",
    "\n",
    "# setting absolute value to make it easier to indentify the strongest correlations with bwght (no matter the sign of them)\n",
    "birthweight_corr.loc[ : , 'bwght'].round(decimals = 2).abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df108e54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Scatter plots</strong>\n",
    "<br>\n",
    "Different scatter plots were developed in this section to identify the relationship or not between the different variables. To make it easy to develop many different scatter plots I defined a function to help set the size of the figure and to easily display the plot without having to call the .show() method every time.\n",
    "<br>\n",
    "In the code I kept only some examples of all the scatter plots developed in order to keep the code clean and easy to read.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ea562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for scatter plots\n",
    "def scatterplots(var, response, data):\n",
    "    \"\"\"\n",
    "\tThis function is designed to generate a scatterplot\n",
    "    Make sure matplotlib.pyplot and seaborn have been imported (as plt and sns).\n",
    "\n",
    "    PARAMETERS\n",
    "\t----------\n",
    "\tvar      : str, continuous variable\n",
    "\tresponse : str, response variable\n",
    "\tdata     : DataFrame of the response and variables\n",
    "\t\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 5))\n",
    "    \n",
    "    sns.scatterplot(x    = var,\n",
    "                    y    = response,\n",
    "                    data = data)\n",
    "    \n",
    "    plt.suptitle(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d186d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cigs\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'cigs',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "# drinks\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'drink',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "# mage\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "# fage\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'fage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# fmaps\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'fmaps',\n",
    "\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94acfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mage only vs bwght\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks only vs bwght\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'drink',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# cigs only vs bwght\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'cigs',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# cigs only vs mwhte (better try box plot)\n",
    "scatterplots(response = 'cigs',\n",
    "\t\t\t var      = 'mwhte',\n",
    "\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2d1e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Box plots</strong>\n",
    "<br>\n",
    "Different box plots were developed in this section to identify the relationship or not between the different categorical variables. For these types of variables the box plots present a better visualization than the scatter plots. To make it easy to develop many different box plots I defined a function to help set the size of the figure and to easily display the plot without having to call the .show() method every time.\n",
    "<br>\n",
    "In the code I kept only some examples of all the scatter plots developed in order to keep the code clean and easy to read.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdaa4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for categorical boxplots\n",
    "def categorical_boxplots(cat_var, response, data):\n",
    "    \"\"\"\n",
    "\tThis function is designed to generate a boxplot for  can be used for categorical variables.\n",
    "    Make sure matplotlib.pyplot and seaborn have been imported (as plt and sns).\n",
    "\n",
    "    PARAMETERS\n",
    "\t----------\n",
    "\tcat_var  : str, categorical variable\n",
    "\tresponse : str, response variable\n",
    "\tdata     : DataFrame of the response and categorical variables\n",
    "\t\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    \n",
    "    sns.boxplot(x    = cat_var,\n",
    "                y    = response,\n",
    "                data = data)\n",
    "    \n",
    "    plt.suptitle(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cigs\n",
    "categorical_boxplots(response = 'bwght',\n",
    "\t\t\t\t\t cat_var  = 'cigs',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks\n",
    "categorical_boxplots(response = 'bwght',\n",
    "\t\t\t\t\t cat_var  = 'drink',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# cigs vs races\n",
    "categorical_boxplots(response = 'cigs',\n",
    "\t\t\t\t\t cat_var  = 'fblck',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks vs races\n",
    "categorical_boxplots(response = 'drink',\n",
    "\t\t\t\t\t cat_var  = 'fblck',\n",
    "\t\t\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e71ff0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Feature Engineering</strong>\n",
    "<br>\n",
    "The first engineering that I used was focused on applying log to the response variable and the features that showed the highest correlation. By doing this I also printed the correlation of the original variables and the engineered ones to determine which ones I would expect to have a bigger impact on my model.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the log of my variables\n",
    "birthweight['log_bwght'] = np.log(birthweight['bwght'] + 0.0001)\n",
    "birthweight['log_cigs'] = np.log(birthweight['cigs'] + 0.0001)\n",
    "\n",
    "# selecting variables to get the correlation\n",
    "log_corr = birthweight.loc[ : , ['cigs',\n",
    "                             'log_cigs',\n",
    "                             'bwght',\n",
    "                             'log_bwght']  ].corr(method = 'pearson')\\\n",
    "                                                 .round(decimals = 2)\n",
    "# getting the correlation\n",
    "log_corr.loc[ ['cigs', 'log_cigs'],\n",
    "              ['bwght', 'log_bwght']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb956eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the log of my variables\n",
    "birthweight['log_drinks'] = np.log(birthweight['drink'] + 0.0001)\n",
    "\n",
    "# selecting variables to get the correlation\n",
    "log_corr = birthweight.loc[ : , ['drink',\n",
    "                             'log_drinks',\n",
    "                             'bwght',\n",
    "                             'log_bwght']  ].corr(method = 'pearson')\\\n",
    "                                                 .round(decimals = 2)\n",
    "# getting the correlation\n",
    "log_corr.loc[ ['drink', 'log_drinks'],\n",
    "\n",
    "             ['bwght', 'log_bwght']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the log of my variables\n",
    "birthweight['log_mage'] = np.log(birthweight['mage'])\n",
    "\n",
    "# selecting variables to get the correlation\n",
    "log_corr = birthweight.loc[ : , ['mage',\n",
    "                             'log_mage',\n",
    "                             'bwght',\n",
    "                             'log_bwght']  ].corr(method = 'pearson')\\\n",
    "                                                 .round(decimals = 2)\n",
    "# getting the correlation\n",
    "log_corr.loc[ ['mage', 'log_mage'],\n",
    "\n",
    "             ['bwght', 'log_bwght']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecf627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating the log of my variables\n",
    "birthweight['log_fage'] = np.log(birthweight['fage'])\n",
    "\n",
    "# selecting variables to get the correlation\n",
    "log_corr = birthweight.loc[ : , ['fage',\n",
    "                             'log_fage',\n",
    "                             'bwght',\n",
    "                             'log_bwght']  ].corr(method = 'pearson')\\\n",
    "                                                 .round(decimals = 2)\n",
    "# getting the correlation\n",
    "log_corr.loc[ ['fage', 'log_fage'],\n",
    "\n",
    "             ['bwght', 'log_bwght']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e59f90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Feature Engineering continued</strong>\n",
    "<br>\n",
    "Later, after returning to the histograms, scatter plots, box plots and correlation matrices developed I began to produce further engineered variables that are explained in the following line of code.\n",
    "<br>\n",
    "These newly engineered variables were also evaluated using the previously mentioned techniques, and only some examples of this are kept in the final code to keep it simple and organized.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating log of omaps and fmaps to identify if another feature can predict\n",
    "# with a high score these variables either with log or without it, because the\n",
    "# values of these variables are correlated with the birthweight\n",
    "birthweight['log_omaps'] = np.log(birthweight['omaps'])\n",
    "birthweight['log_fmaps'] = np.log(birthweight['fmaps'])\n",
    "\n",
    "# creating log of these variables to see if the correlation with birthweight\n",
    "# improves and to determine if their distribution is closer to the normal\n",
    "birthweight['log_meduc'] = np.log(birthweight['meduc'])\n",
    "birthweight['log_monpre'] = np.log(birthweight['monpre'])\n",
    "birthweight['log_npvis'] = np.log(birthweight['npvis'])\n",
    "birthweight['log_feduc'] = np.log(birthweight['feduc'])\n",
    "\n",
    "# creating square of mother age to test it in a model with the normal age\n",
    "# didn't produce the expected results in the end\n",
    "birthweight['mage_2'] = birthweight['mage'] * birthweight['mage']\n",
    "\n",
    "# creating interaction of both parents to test if this interaction generates\n",
    "# healthier babys as they could be more responsible. \n",
    "birthweight['mage_fage'] = birthweight['mage'] * birthweight['fage']\n",
    "\n",
    "# creating bins to identify if having mothers over 40 has an effect on response variable\n",
    "birthweight['mage_over40'] = np.where(birthweight['mage'] >= 40, 1, 0)\n",
    "\n",
    "# creating interactions with the bins for mother's age over 40\n",
    "# these interactions are to identify if the gender of the baby interacts with the age,\n",
    "# if the number of cigarretes or drinks have a different effect related to \n",
    "# the age of the mother\n",
    "birthweight['mage_over40_male'] = birthweight['mage_over40'] * birthweight['male']\n",
    "birthweight['mage_over40_cigs'] = birthweight['mage_over40'] * birthweight['cigs']\n",
    "birthweight['mage_over40_drinks'] = birthweight['mage_over40'] * birthweight['drink']\n",
    "\n",
    "# creating variables to determine if any relation between the first visit to the doctor\n",
    "# and the number of times the mother goes to the doctor during pregnancy has a good\n",
    "# result in predicting the birthweight\n",
    "birthweight['monpre_by_npvis'] = birthweight['monpre'] / birthweight['npvis']\n",
    "birthweight['npvis_by_monpre'] = birthweight['npvis'] / birthweight['monpre']\n",
    "birthweight['npvis_monpre'] = birthweight['npvis'] * birthweight['monpre']\n",
    "\n",
    "# creating a varibale to test if this interaction generates healthier\n",
    "# babys as they could be more responsible. \n",
    "birthweight['both_education'] = birthweight['meduc'] + birthweight['feduc']\n",
    "\n",
    "# creating variables to test if there's an increased effect on birthweight related\n",
    "# to the interaction between mother's age and the number of cigs or drinks\n",
    "birthweight['mage_drinks'] = birthweight['mage'] * birthweight['drink']\n",
    "birthweight['mage_cigs'] = birthweight['mage'] * birthweight['cigs']\n",
    "birthweight['log_mage_drinks'] = np.log(birthweight['mage_drinks'] + 0.0001)\n",
    "birthweight['log_mage_cigs'] = np.log(birthweight['mage_cigs'] + 0.0001)\n",
    "birthweight['mage_plus_drinks'] = birthweight['mage'] + birthweight['drink']\n",
    "birthweight['mage_plus_cigs'] = birthweight['mage'] + birthweight['cigs']\n",
    "birthweight['mage_by_drinks'] = birthweight['mage'] / (birthweight['drink'] + 0.0001)\n",
    "birthweight['drinks_by_mage'] = birthweight['drink'] / birthweight['mage']\n",
    "birthweight['log_mage_by_drinks'] = np.log(birthweight['mage_by_drinks'])\n",
    "birthweight['log_drinks_by_mage'] = np.log(birthweight['drinks_by_mage'] + 0.0001)\n",
    "birthweight['mage_by_cigs'] = birthweight['mage'] / (birthweight['cigs'] + 0.0001)\n",
    "birthweight['cigs_by_mage'] = birthweight['cigs'] / birthweight['mage']\n",
    "birthweight['log_mage_by_cigs'] = np.log(birthweight['mage_by_cigs'])\n",
    "birthweight['log_cigs_by_mage'] = np.log(birthweight['cigs_by_mage'] + 0.0001)\n",
    "birthweight['mage_by_drinks_cigs'] = birthweight['mage'] / (birthweight['drink'] + birthweight['cigs'] + 0.0001)\n",
    "birthweight['drinks_cigs_by_mage'] = (birthweight['drink'] + birthweight['cigs']) / birthweight['mage']\n",
    "birthweight['log_mage_by_drinks_cigs'] = np.log(birthweight['mage_by_drinks_cigs'])\n",
    "birthweight['log_drinks_cigs_by_mage'] = np.log(birthweight['drinks_cigs_by_mage'] + 0.0001)\n",
    "\n",
    "# creating variables to identify if drinks and cigs combined produce a better model\n",
    "birthweight['drinks_plus_cigs'] = birthweight['drink'] + birthweight['cigs']\n",
    "birthweight['drinks_cigs'] = birthweight['drink'] * birthweight['cigs']\n",
    "\n",
    "# creating variables to determine if there's an interaction between mother's age\n",
    "# and cigs or drinks but considering the maximum number of cigs and drinks included\n",
    "# in the dataset. In the end these variables produced the best model, but\n",
    "# they were not really useful as predictor beacuse we wouldn't have the max number\n",
    "# of cigs or drinks when new independent data comes into place or in a complete\n",
    "# different dataset this could result in being not significant\n",
    "birthweight['mage_by_top_cigs'] = birthweight['mage'] / (birthweight['cigs'].max() + 1 - birthweight['cigs'])\n",
    "birthweight['mage_by_top_drinks'] = birthweight['mage'] / (birthweight['drink'].max() + 1 - birthweight['drink'])\n",
    "\n",
    "# creating variables to identify if having both parents from the same race has an effec\n",
    "# on birthweight prediction\n",
    "birthweight['both_race_w'] = birthweight['mwhte'] * birthweight['fwhte']\n",
    "birthweight['both_race_b'] = birthweight['mblck'] * birthweight['fblck']\n",
    "birthweight['both_race_oth'] = birthweight['moth'] * birthweight['foth']\n",
    "\n",
    "# creating variables to identify if having both parents from the different races has\n",
    "# an effec on birthweight prediction\n",
    "birthweight['both_race_mw_fb'] = birthweight['mwhte'] * birthweight['fblck']\n",
    "birthweight['both_race_mw_fo'] = birthweight['mwhte'] * birthweight['foth']\n",
    "birthweight['both_race_mb_fo'] = birthweight['mblck'] * birthweight['foth']\n",
    "birthweight['both_race_fw_mb'] = birthweight['fwhte'] * birthweight['mblck']\n",
    "birthweight['both_race_fw_mo'] = birthweight['fwhte'] * birthweight['moth']\n",
    "birthweight['both_race_fb_mo'] = birthweight['fblck'] * birthweight['moth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b987962",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Analysis of engineered variables</strong>\n",
    "<br>\n",
    "The techniques used were value counts to evaluate the resultant sample sizes, histograms to look at the distributions, correlation matrices to identify the strongest correlations or multi collinearity, scatter plots and box plots to visualize relationship between variables and possible categories or interactions that could be further created.\n",
    "<br>\n",
    "The codes for these charts and the engineered variables were run multiple times using different arguments and creating many different categories and variables.\n",
    "<br>\n",
    "Also, when developing the models, these lines of code were also run to continue visualizing and validating the relationships, and engineering new variables or categories.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568eb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#value counts used for the different categories created to evaluate resultant smaple sizes\n",
    "birthweight['both_race_w'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing correlation matrices for specific variables\n",
    "birthweight_corr = birthweight.corr(method = 'pearson')\n",
    "\n",
    "\n",
    "birthweight_corr.loc[ ['bwght', 'log_bwght', 'feduc', 'mwhte',\n",
    "                       'fwhte', 'meduc', 'mage', 'moth', 'foth'],\n",
    "                      ['bwght', 'log_bwght', 'feduc', 'mwhte',\n",
    "                       'fwhte','meduc', 'mage', 'moth', 'foth']].round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing other correlation matrix for specific variables\n",
    "birthweight_corr = birthweight.corr(method = 'pearson')\n",
    "\n",
    "\n",
    "birthweight_corr.loc[ ['bwght', 'log_bwght', 'drink', 'mage_drinks', 'log_mage_drinks', 'cigs', 'mage_cigs', 'log_mage_cigs', 'mage_plus_drinks', 'mage_plus_cigs'],\n",
    "                      ['bwght', 'log_bwght', 'drink', 'mage_drinks', 'log_mage_drinks', 'cigs', 'mage_cigs', 'log_mage_cigs', 'mage_plus_drinks', 'mage_plus_cigs']].round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ab0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing other correlation matrix for specific variables\n",
    "birthweight_corr = birthweight.corr(method = 'pearson')\n",
    "\n",
    "birthweight_corr.loc[ ['bwght', 'log_bwght', 'mage_by_drinks', 'drinks_by_mage',\n",
    "                       'log_mage_by_drinks', 'log_drinks_by_mage', 'mage_by_cigs',\n",
    "                       'cigs_by_mage', 'log_mage_by_cigs', 'log_cigs_by_mage',\n",
    "                       'mage_by_drinks_cigs', 'drinks_cigs_by_mage',\n",
    "                       'log_mage_by_drinks_cigs', 'log_drinks_cigs_by_mage'],\n",
    "                      ['bwght', 'log_bwght', 'mage_by_drinks', 'drinks_by_mage',\n",
    "                       'log_mage_by_drinks', 'log_drinks_by_mage', 'mage_by_cigs',\n",
    "                       'cigs_by_mage', 'log_mage_by_cigs', 'log_cigs_by_mage',\n",
    "                       'mage_by_drinks_cigs', 'drinks_cigs_by_mage',\n",
    "                       'log_mage_by_drinks_cigs', 'log_drinks_cigs_by_mage']].round(decimals = 2).abs().sort_values(ascending = False, by = 'bwght')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fage vs log\n",
    "scatterplots(response = 'log_bwght',\n",
    "\t\t\t var      = 'fage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# mage vs log\n",
    "scatterplots(response = 'log_bwght',\n",
    "\t\t\t var      = 'mage',\n",
    "\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### drinks\n",
    "# mage and drinks\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage_drinks',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# mage and drinks vs log\n",
    "scatterplots(response = 'log_bwght',\n",
    "\t\t\t var      = 'mage_drinks',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# mage only\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks only\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'drink',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "######################### cigs\n",
    "\n",
    "# mage and cigs\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage_cigs',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# mage and cigs vs log\n",
    "scatterplots(response = 'log_bwght',\n",
    "\t\t\t var      = 'mage_cigs',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# mage only\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'mage',\n",
    "\t\t\t data     = birthweight)\n",
    "\n",
    "# cigs only\n",
    "scatterplots(response = 'bwght',\n",
    "\t\t\t var      = 'cigs',\n",
    "\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2664fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mage_drinks\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'mage_drinks',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Mothers age interaction with number of drinks\")\n",
    "plt.xlabel(xlabel = \"Mothers age interaction with number of drinks\")\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# log_mage_drinks\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'log_mage_drinks',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Log Distribution of Mothers age interaction with number of drinks\")\n",
    "plt.xlabel(xlabel = \"Log of Mothers age interaction with number of drinks\")\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# mage_cigs\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'mage_cigs',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Original Distribution of Mothers age interaction with number of cigs\")\n",
    "plt.xlabel(xlabel = \"Mothers age interaction with number of cigs\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()\n",
    "\n",
    "# log_mage_cigs\n",
    "sns.histplot(data  = birthweight,\n",
    "             x     = 'log_mage_cigs',\n",
    "             kde    = True)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"Log Distribution of Mothers age interaction with number of cigs\")\n",
    "plt.xlabel(xlabel = \"Log of Mothers age interaction with number of drinks\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cigs\n",
    "categorical_boxplots(response = 'bwght',\n",
    "\t\t\t\t\t cat_var  = 'cigs',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "# cigs\n",
    "categorical_boxplots(response = 'log_bwght',\n",
    "\t\t\t\t\t cat_var  = 'cigs',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "# cigs\n",
    "categorical_boxplots(response = 'log_bwght',\n",
    "\t\t\t\t\t cat_var  = 'log_cigs',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# drinks\n",
    "categorical_boxplots(response = 'bwght',\n",
    "\t\t\t\t\t cat_var  = 'drink',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks\n",
    "categorical_boxplots(response = 'log_bwght',\n",
    "\t\t\t\t\t cat_var  = 'drink',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# drinks\n",
    "categorical_boxplots(response = 'log_bwght',\n",
    "\t\t\t\t\t cat_var  = 'log_drinks',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "########################################################\n",
    "# mothers race and educ \n",
    "\n",
    "# mwhte\n",
    "categorical_boxplots(response = 'meduc',\n",
    "\t\t\t\t\t cat_var  = 'mwhte',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# mblck\n",
    "categorical_boxplots(response = 'meduc',\n",
    "\t\t\t\t\t cat_var  = 'mblck',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# moth\n",
    "categorical_boxplots(response = 'meduc',\n",
    "\t\t\t\t\t cat_var  = 'moth',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "###################################\n",
    "# fathers race and educ \n",
    "\n",
    "# mwhte\n",
    "categorical_boxplots(response = 'feduc',\n",
    "\t\t\t\t\t cat_var  = 'fwhte',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# mblck\n",
    "categorical_boxplots(response = 'feduc',\n",
    "\t\t\t\t\t cat_var  = 'fblck',\n",
    "\t\t\t\t\t data     = birthweight)\n",
    "\n",
    "# moth\n",
    "categorical_boxplots(response = 'feduc',\n",
    "\t\t\t\t\t cat_var  = 'foth',\n",
    "\t\t\t\t\t data     = birthweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36039aa1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>First OLS model</strong>\n",
    "<br>\n",
    "In the following section I created a linear regression using different combinations of original and engineered features to look for p-values, and possible new variables to be developed.  \n",
    "<br>\n",
    "As mentioned before, this was an on going process coming back to this section and the creation and validation of new variables and interactions.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e92173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to have my columns in the format required for the OLS\n",
    "for col in birthweight.columns:\n",
    "    print(col, end = ' + ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE the model object\n",
    "lm_best = smf.ols(formula =  \"\"\"bwght ~\n",
    "cigs +\n",
    "drink +\n",
    "drinks_cigs\"\"\",\n",
    "                                data = birthweight)\n",
    "\n",
    "# FIT the data into the model object\n",
    "results = lm_best.fit()\n",
    "\n",
    "# SUMMARY output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a595e97",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Regression models</strong>\n",
    "<br>\n",
    "In the following sections I modeled many regression models using OLS, Lasso and ARD. I used test, train split to divide my dataset and be able to train my data with different features and then test it with three models.\n",
    "<br>\n",
    "As mentioned before, this was an on going process coming back to this section and the creation and validation of new variables and interactions.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27664e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# preparing the features by dropping the response variable and its log that was created before\n",
    "birthweight_data = birthweight.drop([\"bwght\",\n",
    "                                     \"log_bwght\"],\n",
    "                                     axis = 1)\n",
    "\n",
    "# preparing response variables, original and log\n",
    "birthweight_target = birthweight.loc[ : , \"bwght\"]\n",
    "log_birthweight_target = birthweight.loc[ : , \"log_bwght\"]\n",
    "\n",
    "\n",
    "# preparing training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            birthweight_data,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# checking the shapes of the datasets\n",
    "print(f\"\"\"\n",
    "Training Data\n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9e1cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "The next line of code was used to set my x_variables intended to be used in my different regression models. This section was constantly modified to try different features to obtain the best possible model.\n",
    "<br>\n",
    "As mentioned before, this was an on going process coming back to this section and the creation and validation of new variables and interactions.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4971941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring set of x-variables\n",
    "#x_variables = ['meduc', 'fage', 'male', 'mwhte', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_omaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_drinks', 'mage_cigs', 'mage_plus_drinks', 'mage_plus_cigs', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'fage', 'male', 'mwhte', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_omaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_drinks', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'fage', 'male', 'mwhte', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_omaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'fage', 'male', 'mwhte', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'male', 'mwhte', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'male', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_monpre', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'male', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'fmaps', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'male', 'moth', 'm_meduc', 'm_npvis', 'm_feduc', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'male', 'moth', 'm_meduc', 'm_npvis', 'log_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'moth', 'm_meduc', 'm_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'moth', 'm_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'm_npvis', 'log_feduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'm_npvis', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_mage_by_drinks']\n",
    "\n",
    "#x_variables = ['meduc', 'mage_cigs', 'mage_plus_drinks', 'drinks_by_mage']\n",
    "\n",
    "#x_variables = ['mage_cigs', 'mage_plus_drinks', 'drinks_by_mage', 'log_meduc']\n",
    "\n",
    "# best ARD x_variables = ['cigs', 'drink', 'both_race_w', 'both_race_b', 'mage_by_top_cigs', 'meduc']\n",
    "\n",
    "# equal best ARD x_variables = ['cigs', 'drink', 'mage_by_top_cigs', 'meduc']\n",
    "\n",
    "# best OLS x_variables = ['cigs', 'drink', 'both_race_w', 'both_race_b', 'mage_by_top_cigs']\n",
    "\n",
    "# second best OLS x_variables = ['cigs', 'drink', 'both_race_w', 'mage_by_top_cigs'] \n",
    "\n",
    "# second best ARD x_variables = ['cigs', 'drink', 'mage_by_top_cigs', 'feduc']\n",
    "\n",
    "# also good model - x_variables = ['cigs', 'drink', 'meduc']\n",
    "\n",
    "# also good model x_variables = ['cigs', 'drink', 'mage_by_top_cigs']\n",
    "\n",
    "# also good model x_variables = ['cigs', 'drink', 'both_race_w', 'meduc']\n",
    "\n",
    "x_variables = ['cigs', 'drink', 'both_race_w', 'both_race_b', 'meduc']\n",
    "\n",
    "# looping to make x-variables suitable for statsmodels\n",
    "for val in x_variables:\n",
    "    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699791a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging X_train and y_train so that they can be used in statsmodels\n",
    "birthweight_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "#building model\n",
    "lm_best = smf.ols(formula =  \"\"\"bwght ~\n",
    "cigs +\n",
    "drink +\n",
    "both_race_w +\n",
    "both_race_b +\n",
    "meduc\"\"\",\n",
    "data = birthweight_train)\n",
    "\n",
    "\n",
    "#fitting model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "#printing summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba37e9d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>Preparing data for the models</strong>\n",
    "<br>\n",
    "I set my data to include only the x_variables previously defined and my target data to include only my response variable (also evaluated several times with log).\n",
    "<br>\n",
    "Two different train-test-splits were created to be able to run my models on the full data and also only on my x_variables. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e835d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying modelin scikit-learn\n",
    "\n",
    "# preparing x-variables from the OLS model, this is also used in other models to test with reduced features\n",
    "ols_data = birthweight.loc[ : , x_variables]\n",
    "\n",
    "\n",
    "# preparing response variable\n",
    "birthweight_target = birthweight.loc[ : , \"bwght\"]\n",
    "\n",
    "\n",
    "###############################################\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset (normal Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            birthweight_data,     # x-variables\n",
    "            birthweight_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# OLS p-value x-dataset (normal Y)\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            ols_data,         # x-variables\n",
    "            birthweight_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0501ace5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>OLS model</strong>\n",
    "<br>\n",
    "Running the OLS with all the features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data, full dataset\n",
    "lr_fit = lr.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, full dataset\n",
    "lr_pred = lr_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_FULL, y_train_FULL).round(4))  # using R-square\n",
    "print('OLS Testing Score  :',  lr.score(x_test_FULL, y_test_FULL).round(4)) # using R-square\n",
    "\n",
    "lr_train_score = lr.score(x_train_FULL, y_train_FULL).round(4)\n",
    "lr_test_score = lr.score(x_test_FULL, y_test_FULL).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb58d6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>OLS model</strong>\n",
    "<br>\n",
    "Running the OLS with the x_variables features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49999208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data, only with the x_variables defined\n",
    "# for simplicity the name OLS is kept for future models\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, only with the x_variables defined\n",
    "# for simplicity the name OLS is kept for future models\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(4))  # using R-square\n",
    "print('OLS Testing Score  :',  lr.score(x_test_OLS, y_test_OLS).round(4)) # using R-square\n",
    "\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(4)\n",
    "lr_test_score = lr.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(birthweight_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44f764",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Lasso Regression</strong>\n",
    "<br>\n",
    "Running the Lasso Regression with the all the features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5cb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "lasso_model = Lasso(alpha     = 1,\n",
    "                    normalize = True)\n",
    "\n",
    "\n",
    "# FITTING to training data, full dataset\n",
    "lasso_fit = lasso_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, full dataset\n",
    "lasso_pred = lasso_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_FULL, y_train_FULL).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_FULL, y_test_FULL).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b801ea1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Lass Regression</strong>\n",
    "<br>\n",
    "Running the Lasso Regression with the x_variables features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76235e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "lasso_model = Lasso(alpha     = 1,\n",
    "                    normalize = True)\n",
    "\n",
    "\n",
    "# FITTING to the training data, only with the x_variables defined\n",
    "# for simplicity the name OLS was kept\n",
    "lasso_fit = lasso_model.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, only with the x_variables defined\n",
    "# for simplicity the name OLS was kept\n",
    "lasso_pred = lasso_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_OLS, y_train_OLS).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_OLS, y_test_OLS).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "# this part has to be modified to include only the [x_varibales] when running the OLS split,\n",
    "# or to not include [x_variables] when running the full split\n",
    "lasso_model_values = zip(birthweight_data[x_variables].columns, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping coefficients that are equal to zero\n",
    "# this is run when the full dataset is used in the Lasso Regression to \n",
    "# determine the variables that could be removed from the x_variables\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            lasso_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f9ae0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>ARD Regression</strong>\n",
    "<br>\n",
    "Running the ARD Regression with all the features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4128b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "# INSTANTIATING a model object\n",
    "ard_model = ARDRegression()\n",
    "\n",
    "\n",
    "# FITTING the training data, full dataset\n",
    "ard_fit = ard_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, full dataset\n",
    "ard_pred = ard_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_FULL, y_train_FULL).round(4))\n",
    "print('Testing Score :', ard_model.score(x_test_FULL, y_test_FULL).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_FULL, y_train_FULL).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_FULL, y_test_FULL).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "# INSTANTIATING a model object\n",
    "ard_model = ARDRegression()\n",
    "\n",
    "\n",
    "# FITTING the training data, only with the x_variables defined\n",
    "# for simplicity the name OLS was kept\n",
    "ard_fit = ard_model.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data, only with the x_variables defined\n",
    "# for simplicity the name OLS was kept\n",
    "ard_pred = ard_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Testing Score :', ard_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_OLS, y_train_OLS).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "# this part has to be modified to include only the [x_varibales] when running the OLS split,\n",
    "# or to not include [x_variables] when running the full split\n",
    "ard_model_values = zip(birthweight_data[x_variables], ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping coefficients that are equal to zero\n",
    "# this is run when the full dataset is used in the Lasso Regression to \n",
    "# determine the variables that could be removed from the x_variables\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in ard_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            ard_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c53b55",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Results of OLS, Lasso and ARD regressions</strong>\n",
    "<br>\n",
    "I compared every model results considering the test score, train score and the gap between them.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score      Train-Test Gap\n",
    "-----      -----------      ----------      ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}           {lr_test_gap}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}            {lasso_test_gap}\n",
    "ARD        {ard_train_score}           {ard_test_score}           {ard_test_gap}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso', 'ARD'],\n",
    "           \n",
    "    'Training' : [lr_train_score, lasso_train_score,\n",
    "                                   ard_train_score],\n",
    "           \n",
    "    'Testing'  : [lr_test_score, lasso_test_score,\n",
    "                                   ard_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr_test_gap, lasso_test_gap,\n",
    "                                        ard_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr_model_lst), len(lasso_model_lst),\n",
    "                                    len(ard_model_lst)],\n",
    "                    \n",
    "    'Model' : [lr_model_lst, lasso_model_lst, ard_model_lst]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# # sending model results to Excel\n",
    "# model_performance.to_excel('./Model_results/linear_model_performance.xlsx',\n",
    "#                            index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dc756",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>Model predictions</strong>\n",
    "<br>\n",
    "I decided to extract my model predictions and save them in an Excel file. Then I used this file to try to identify even more improvements for my model by looking at the highest and lowest residuals from my different models.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_results = pd.DataFrame(data = {\n",
    "    'Original Birthweight' : y_test_FULL,\n",
    "    'LR Predictions'       : lr_pred.round(decimals = 2),\n",
    "    'Lasso Predictions'    : lasso_pred.round(decimals = 2),\n",
    "    'ARD Predictions'      : ard_pred.round(decimals = 2),\n",
    "    'LR Deviation'         : lr_pred.round(decimals = 2) - y_test_FULL,\n",
    "    'Lasso Deviation'      : lasso_pred.round(decimals = 2) - y_test_FULL,\n",
    "    'ARD Deviation'        : ard_pred.round(decimals = 2) - y_test_FULL,\n",
    "    })\n",
    "\n",
    "\n",
    "# prediction_results.to_excel(excel_writer = './Model_results/linear_model_predictions.xlsx',\n",
    "#                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71296880",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "<strong>KNN Regression</strong>\n",
    "<br>\n",
    "I developed a KNN Regression model by either not scaling my data and then by scaling it. I compared the results from these two options and also improved them by finding the optimal number of neighbors to be used.\n",
    "<br>\n",
    "Since non of the outputs obtained by using the KNN regression resulted in better scores and gap reduction between test and train, I decided to not include the outputs of these models in my previous comparisons.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# INSTANTIATING StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING scaler with data, using only my x_variables stored in ols_data\n",
    "scaler.fit(ols_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING data after fit into scaled\n",
    "x_scaled = scaler.transform(ols_data)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "x_scaled_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "x_scaled_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding labels to scaled DataFrame\n",
    "x_scaled_df.columns = ols_data.columns\n",
    "\n",
    "#  comparing pre- and post-scaling of data\n",
    "print(f\"\"\"\n",
    "Dataset BEFORE Scaling\n",
    "----------------------\n",
    "{np.var(ols_data)}\n",
    "\n",
    "\n",
    "Dataset AFTER Scaling\n",
    "----------------------\n",
    "{np.var(x_scaled_df)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f538029",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>k-Nearest Neighbors with Non-Standardized Data</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ada692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data with all features\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            ols_data,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36370e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# INSTANTIATING KNN model object\n",
    "knn_reg = KNeighborsRegressor(algorithm = 'auto',\n",
    "                              n_neighbors = 7)\n",
    "\n",
    "\n",
    "# FITTING to training data\n",
    "knn_fit = knn_reg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "knn_reg_pred = knn_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING results\n",
    "print('KNN Training Score:', knn_reg.score(x_train, y_train).round(4))\n",
    "print('KNN Testing Score :',  knn_reg.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_reg_score_train = knn_reg.score(x_train, y_train).round(4)\n",
    "knn_reg_score_test  = knn_reg.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_reg_score_train - knn_reg_score_test).round(4))\n",
    "knn_reg_test_gap = abs(knn_reg_score_train - knn_reg_score_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy     = []\n",
    "\n",
    "\n",
    "# building a visualization of 1 to 50 neighbors\n",
    "neighbors_settings = range(1, 51)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# plotting the visualization\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_opt = KNeighborsRegressor(algorithm   = 'auto',\n",
    "                              n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "# FITTING model based on the training data\n",
    "knn_opt_fit = knn_opt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_opt_pred = knn_opt_fit.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# SCORING results\n",
    "print('KNN Training Score:', knn_opt.score(x_train, y_train).round(4))\n",
    "print('KNN Testing Score :',  knn_opt.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_opt_score_train = knn_opt.score(x_train, y_train).round(4)\n",
    "knn_opt_score_test  = knn_opt.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_opt_score_train - knn_opt_score_test).round(4))\n",
    "knn_opt_test_gap = abs(knn_opt_score_train - knn_opt_score_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d063c9f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Splitting the scaled data into my test and train sets</strong>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_STAND, x_test_STAND, y_train_STAND, y_test_STAND = train_test_split(\n",
    "            x_scaled_df,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "\n",
    "# building a visualization of 1 to 50 neighbors\n",
    "neighbors_settings = range(1, 51)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(x_train_STAND, y_train_STAND)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(x_train_STAND, y_train_STAND))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(x_test_STAND, y_test_STAND))\n",
    "\n",
    "\n",
    "# plotting the visualization\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy,     label = \"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# finding the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb667eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_stand = KNeighborsRegressor(algorithm = 'auto',\n",
    "                                n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "# FITTING model based on the training data\n",
    "knn_stand_fit = knn_stand.fit(x_train_STAND, y_train_STAND)\n",
    "\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_stand_pred = knn_stand_fit.predict(x_test_STAND)\n",
    "\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('KNN Training Score:', knn_stand.score(x_train_STAND, y_train_STAND).round(4))\n",
    "print('KNN Testing Score :',  knn_stand.score(x_test_STAND, y_test_STAND).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_stand_score_train = knn_stand.score(x_train_STAND, y_train_STAND).round(4)\n",
    "knn_stand_score_test  = knn_stand.score(x_test_STAND, y_test_STAND).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_stand_score_train - knn_stand_score_test).round(4))\n",
    "knn_stand_test_gap = abs(knn_stand_score_train - knn_stand_score_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef605070",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Model results for k-Nearest Neighbors</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2344eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "KNN Model             Neighbors     Train Score      Test Score\n",
    "----------------      ---------     ----------       ----------\n",
    "Non-Standardized      1             {knn_reg_score_train}           {knn_reg_score_test}\n",
    "Non-Standardized      14            {knn_opt_score_train}           {knn_opt_score_test}\n",
    "Standardized          6             {knn_stand_score_train}           {knn_stand_score_test}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['KNN_Not_Standardized', 'KNN_Not_Standardized_Opt', 'KNN_Standardized_Opt'],\n",
    "           \n",
    "    \n",
    "    'Training' : [knn_reg_score_train,\n",
    "                  knn_opt_score_train,\n",
    "                  knn_stand_score_train],\n",
    "           \n",
    "    \n",
    "    'Testing'  : [knn_reg_score_test,\n",
    "                  knn_opt_score_test,\n",
    "                  knn_stand_score_test],\n",
    "                    \n",
    "    \n",
    "    'Train-Test Gap' : [knn_reg_test_gap,\n",
    "                        knn_opt_test_gap,\n",
    "                        knn_stand_test_gap],\n",
    "                   \n",
    "    \n",
    "    'Model Size' : [\"NA\", \"NA\", \"NA\"],\n",
    "                    \n",
    "    'Model'      : [\"NA\", \"NA\", \"NA\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d6030",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "<strong>Final model output and selection</strong>\n",
    "<br>\n",
    "The following table shows the summary of my models and the selected model to use to predict the birth weight.\n",
    "<br>\n",
    "As mentioned before, the KNN model is not included given that it produced results with low scores and big gaps between the test and train scores.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score      Train-Test Gap\n",
    "-----      -----------      ----------      ----------\n",
    "OLS**      {lr_train_score}           {lr_test_score}           {lr_test_gap}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}            {lasso_test_gap}\n",
    "ARD        {ard_train_score}           {ard_test_score}           {ard_test_gap}\n",
    "\n",
    "Note: My final model selection is marked by using double **\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
